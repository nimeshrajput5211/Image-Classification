{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To show Multiline Output within single window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a structure for Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D(padding=(1,1),input_shape=(224,224,3)))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4096, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=4096, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VGG network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG_16('vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the layers and length of the layers length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.ZeroPadding2D at 0x80f412940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f412be0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x8065e71d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f4120f0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x80f447908>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f48a5f8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f48a940>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f47a7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f4ab2b0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x80f4bea58>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f50a8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f50a860>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f4fb898>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f52c6d8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f53b940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f569898>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x80f57a780>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f5acef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f5dbe10>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f5db4e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f60bba8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f6197f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f62d630>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x80f65ca90>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f68f320>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f67ceb8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f69df60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f6acf98>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x80f6ddcf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x80f6feef0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x80f6eceb8>,\n",
       " <keras.layers.core.Flatten at 0x80f74ea90>,\n",
       " <keras.layers.core.Dense at 0x80f73a860>,\n",
       " <keras.layers.core.Dropout at 0x80f76d748>,\n",
       " <keras.layers.core.Dense at 0x80f75cc88>,\n",
       " <keras.layers.core.Dropout at 0x80f7c9978>,\n",
       " <keras.layers.core.Dense at 0x80f7c98d0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers\n",
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to read a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "def read_image(f):\n",
    "    im = Image.open(f)\n",
    "    im = im.resize((size, size), PIL.Image.NEAREST)\n",
    "    im = np.asarray(im, dtype='float64')\n",
    "    im[:,:,0] -= 103.939  ## Mean value for individual channel (RGB) \n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    im = im.reshape(1,224,224,3)\n",
    "    \n",
    "    return(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a single image from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "im = read_image('1.jpg')\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with a Sequential model\n",
    "get_33rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[32].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "layer_output = get_33rd_layer_output([im])[0]\n",
    "print(layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preparing the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_files = []\n",
    "for root, dirs, files in os.walk('C:/Users/NY 5211/Downloads/DeepLearningAssignment/train/'):\n",
    "    img_files.extend(files)\n",
    "    #print(files)\n",
    "    #len(files)\n",
    "    #for name in dirs:\n",
    "        #print(os.path.join(root,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the length of the image file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(img_files)\n",
    "#print(img_files)#\n",
    "#print(root)\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all images from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 120\n",
      "Sample images taken: 120\n",
      "Sample Length 120\n",
      "Reading train images ...\n",
      "Read 0 images\n",
      "Read 24 images\n",
      "Read 48 images\n",
      "Read 72 images\n",
      "Read 96 images\n",
      "Done reading all images\n"
     ]
    }
   ],
   "source": [
    "n_files = len(img_files)\n",
    "print('Total number of images:', n_files)\n",
    "\n",
    "train_size = 120\n",
    "sample_size = min(n_files,train_size)\n",
    "print('Sample images taken:', sample_size)\n",
    "sample = [img_files[i] for i in np.random.choice(len(files),size=sample_size, replace=True)]\n",
    "i=0\n",
    "print(\"Sample Length\",len(sample))\n",
    "x_train = []\n",
    "y_train = []\n",
    "print('Reading train images ...')\n",
    "for file in sample:\n",
    "    if(i%24==0):\n",
    "        print('Read {} images'.format(i))\n",
    "    im = read_image('C:/Users/NY 5211/Downloads/DeepLearningAssignment/train/club_train/'+file)\n",
    "    temp = get_33rd_layer_output([im])[0]\n",
    "    x_train.append(temp[0])\n",
    "    if file[:2]=='c0':\n",
    "        y_train.extend(['0'])\n",
    "    elif file[:2]=='c1':\n",
    "        y_train.extend(['1'])\n",
    "    elif file[:2]=='c2':\n",
    "        y_train.extend(['2'])             \n",
    "    elif file[:2]=='c3':\n",
    "        y_train.extend(['3'])\n",
    "    elif file[:2]=='c4':\n",
    "        y_train.extend(['4'])\n",
    "    i+=1\n",
    "\n",
    "print(\"Done reading all images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check the shape of the both file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4096) x_train Shape\n",
      "(120, 5) y_train Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "print(x_train.shape, 'x_train Shape')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train.shape, 'y_train Shape')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a normal MLP model for given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=1024, input_dim=4096, activation='relu'))\n",
    "mlp.add(Dropout(rate=0.1))\n",
    "mlp.add(Dense(units=512, activation='relu'))\n",
    "mlp.add(Dropout(rate=0.1))\n",
    "mlp.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.01)\n",
    "mlp.compile(optimizer=adam, \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 10.5895 - acc: 0.2250\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 12.4915 - acc: 0.2250\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 12.6258 - acc: 0.2167\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 12.6258 - acc: 0.2167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x80fa78748>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preparing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_test_file = []\n",
    "for test_root, test_dirs, test_files in os.walk('C:/Users/NY 5211/Downloads/DeepLearningAssignment/test/'):\n",
    "    img_test_file.extend(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_100026.jpg', 'img_100050.jpg', 'img_100074.jpg', 'img_100145.jpg', 'img_100191.jpg', 'img_100257.jpg', 'img_100312.jpg', 'img_91724.jpg', 'img_91729.jpg', 'img_91761.jpg', 'img_91769.jpg', 'img_91804.jpg', 'img_91849.jpg', 'img_91906.jpg', 'img_91933.jpg', 'img_91939.jpg', 'img_91993.jpg', 'img_92009.jpg', 'img_92022.jpg', 'img_92088.jpg', 'img_93664.jpg', 'img_93682.jpg', 'img_93732.jpg', 'img_93755.jpg', 'img_93846.jpg', 'img_93875.jpg', 'img_93881.jpg', 'img_93900.jpg', 'img_93970.jpg', 'img_93987.jpg', 'img_94040.jpg', 'img_94092.jpg', 'img_94136.jpg', 'img_96710.jpg', 'img_96719.jpg', 'img_96770.jpg', 'img_96824.jpg', 'img_96924.jpg', 'img_97064.jpg', 'img_97132.jpg', 'img_97201.jpg', 'img_97226.jpg', 'img_97243.jpg', 'img_97326.jpg', 'img_97380.jpg', 'img_97440.jpg', 'img_98387.jpg', 'img_98440.jpg', 'img_98489.jpg', 'img_98507.jpg', 'img_98532.jpg', 'img_98564.jpg', 'img_98634.jpg', 'img_98647.jpg', 'img_98739.jpg', 'img_98746.jpg', 'img_98787.jpg', 'img_98916.jpg', 'img_98924.jpg', 'img_99696.jpg', 'img_99715.jpg', 'img_99779.jpg', 'img_99785.jpg', 'img_99846.jpg', 'img_99971.jpg']\n",
      "65\n",
      "['img_100026.jpg', 'img_100050.jpg', 'img_100074.jpg', 'img_100145.jpg', 'img_100191.jpg', 'img_100257.jpg', 'img_100312.jpg', 'img_91724.jpg', 'img_91729.jpg', 'img_91761.jpg', 'img_91769.jpg', 'img_91804.jpg', 'img_91849.jpg', 'img_91906.jpg', 'img_91933.jpg', 'img_91939.jpg', 'img_91993.jpg', 'img_92009.jpg', 'img_92022.jpg', 'img_92088.jpg', 'img_93664.jpg', 'img_93682.jpg', 'img_93732.jpg', 'img_93755.jpg', 'img_93846.jpg', 'img_93875.jpg', 'img_93881.jpg', 'img_93900.jpg', 'img_93970.jpg', 'img_93987.jpg', 'img_94040.jpg', 'img_94092.jpg', 'img_94136.jpg', 'img_96710.jpg', 'img_96719.jpg', 'img_96770.jpg', 'img_96824.jpg', 'img_96924.jpg', 'img_97064.jpg', 'img_97132.jpg', 'img_97201.jpg', 'img_97226.jpg', 'img_97243.jpg', 'img_97326.jpg', 'img_97380.jpg', 'img_97440.jpg', 'img_98387.jpg', 'img_98440.jpg', 'img_98489.jpg', 'img_98507.jpg', 'img_98532.jpg', 'img_98564.jpg', 'img_98634.jpg', 'img_98647.jpg', 'img_98739.jpg', 'img_98746.jpg', 'img_98787.jpg', 'img_98916.jpg', 'img_98924.jpg', 'img_99696.jpg', 'img_99715.jpg', 'img_99779.jpg', 'img_99785.jpg', 'img_99846.jpg', 'img_99971.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(img_test_file)\n",
    "print(len(test_files))\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading the all images from the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 65\n",
      "Sample images taken: 65\n",
      "Sample Length 65\n",
      "Reading train images ...\n"
     ]
    }
   ],
   "source": [
    "n_test_files = len(img_test_file)\n",
    "print('Total number of images:', n_test_files)\n",
    "\n",
    "test_size = 65\n",
    "sample_test_size = min(n_test_files,test_size)\n",
    "print('Sample images taken:', sample_test_size)\n",
    "sample_test = [img_test_file[i] for i in np.random.choice(len(test_files),size=sample_test_size, replace=True)]\n",
    "i=0\n",
    "print(\"Sample Length\",len(sample_test))\n",
    "x_test = []\n",
    "print('Reading train images ...')\n",
    "for file_test in sample_test:\n",
    "    im1 = read_image('C:/Users/NY 5211/Downloads/DeepLearningAssignment/test/'+file_test)\n",
    "    temp1 = get_33rd_layer_output([im1])[0]\n",
    "    x_test.append(temp1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the data using predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mlp.predict_classes(np.array(x_test))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Convert Dependent variable as per the given format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = np.array(pred).tolist() ## Convert Numpy array list to simple list\n",
    "newlist = []\n",
    "\n",
    "for i in ans:\n",
    "    if i == 2:\n",
    "        i = 'c2'\n",
    "    elif i == 3:\n",
    "        i = 'c3'\n",
    "    elif i == 4:\n",
    "        i = 'c4'\n",
    "    elif i == 0:\n",
    "        i = 'c0'\n",
    "    elif i == 1:\n",
    "        i = 'c1'\n",
    "    newlist.append(i)\n",
    "    \n",
    "ans = newlist\n",
    "len(ans)       \n",
    "#print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the list into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_frame = pd.DataFrame({'FileName': test_files, 'Label':ans})\n",
    "len(sub_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generates the final submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.to_csv(sub_frame,\"Submission.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
